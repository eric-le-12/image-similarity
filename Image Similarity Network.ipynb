{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torchtoolbox\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check torch cuda is available\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please change architecture settings below\n",
    "arch_name = 'efficientnet-b4'\n",
    "batch_size = 16\n",
    "optimizer_name = \"Adam\"\n",
    "lr = 0.0002\n",
    "num_epoch = 50\n",
    "from datetime import datetime\n",
    "time_str_name = str(datetime.now().strftime(\"%Y%m%d-%H%M\"))+'_model.pt'\n",
    "\n",
    "model_name = os.path.join('../models',time_str_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataset class and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the class for image similarity network\n",
    "# employing a Custom Dataset Class\n",
    "class TripletDataset():\n",
    "    def __init__(self,dataframe,transform,transform_random):\n",
    "        self.data = shuffle(dataframe)\n",
    "        self.transform = transform\n",
    "        self.transform_random = transform_random\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx,0]\n",
    "        label = self.data.iloc[idx,1]\n",
    "        positive = self.data[self.data.labels == label]\n",
    "        negative = self.data[self.data.labels != label]\n",
    "        postivie = positive.sample(1)\n",
    "        negative = negative.sample(1)\n",
    "        positive_name = postivie.iloc[0,0]\n",
    "        negative_name = negative.iloc[0,0]\n",
    "        query = Image.open(img_name)\n",
    "        pos = Image.open(positive_name)\n",
    "        neg = Image.open(negative_name)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            query = self.transform(query)\n",
    "            pos = self.transform_random(pos)\n",
    "            neg = self.transform_random(neg)\n",
    "        return query,pos,neg,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building transform\n",
    "from torchvision import transforms, models\n",
    "from torchtoolbox.transform import RandomGaussianNoise\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.RandomResizedCrop(size=64),\n",
    "        transforms.RandomHorizontalFlip(p=1),\n",
    "        transforms.RandomPerspective(p=1),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "no_transform =transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "         transforms.ToTensor(),\n",
    "    ])\n",
    "random_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.RandomApply([transforms.RandomHorizontalFlip(p=0.5),transforms.RandomPerspective(),transforms.RandomVerticalFlip()]),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "import math\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = EfficientNet.from_pretrained(arch_name)\n",
    "num_features = model._fc.in_features\n",
    "model._fc = nn.Sequential(torch.nn.Linear(num_features,256,bias = True))\n",
    "model = model.to(DEVICE)\n",
    "for param in model.parameters():\n",
    "    param.require_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1,beta=0.5, p=0.2):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.p=0.2\n",
    "        self.beta= beta\n",
    "        \n",
    "    def calc_euclidean(self, x1, x2):\n",
    "        return (x1 - x2).pow(2).sum(1)\n",
    "    \n",
    "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n",
    "        p = self.p\n",
    "        distance_positive = self.calc_euclidean(anchor, positive)\n",
    "        distance_negative = self.calc_euclidean(anchor, negative)\n",
    "        distance_pos_neg = self.calc_euclidean(positive, negative)\n",
    "        distance_postive_reverse = self.calc_euclidean(positive, anchor)\n",
    "        losses = torch.relu(distance_positive - p*distance_negative + self.margin) + torch.relu(distance_postive_reverse - distance_pos_neg + self.margin)\n",
    "\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtoolbox.nn import LabelSmoothingLoss\n",
    "\n",
    "criterion= TripletLoss(margin=1.0,beta=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0002)\n",
    "scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True,min_lr=0.0000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hieu/notebooks'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logging\n",
    "import logging\n",
    "file_name = model_name + \".txt\"\n",
    "f = open(os.path.join('../logs', file_name), \"w+\")\n",
    "f.close()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create console handler and set level to info\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "handler.terminator = \"\"\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# create error file handler and set level to error\n",
    "handler = logging.FileHandler('../logs/'+file_name, \"w\", encoding=None, delay=\"true\")\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "handler.terminator = \"\"\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    4192\n",
      "0     951\n",
      "Name: labels, dtype: int64\n",
      "1    951\n",
      "0    951\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv('../csv_files/full_data_filtered.csv',usecols=[\"file_names\",\"labels\",\"sources\"])\n",
    "train_data = train_data[train_data['sources'].isin(['/data1/hold_gun_youtube','/home/hieu/high_qual'])]\n",
    "print(train_data.labels.value_counts())\n",
    "\n",
    "train_data = train_data.groupby('labels').apply(lambda x: x.sample(n=951)).reset_index(drop = True)\n",
    "print(train_data.labels.value_counts())\n",
    "from sklearn.utils import shuffle\n",
    "train_set = TripletDataset(train_data,train_transform,random_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size,shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/data1/hold_gun_youtube    1390\n",
       "/home/hieu/high_qual        512\n",
       "Name: sources, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['sources'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 50 , Similarity Loss : 0.8196947057540485 \n",
      " Epoch 1 / 50 , Similarity Loss : 0.8196947057540485 \n",
      " Epoch 1 / 50 , Similarity Loss : 0.8196947057540485 \n",
      " Epoch 1 / 50 , Similarity Loss : 0.8196947057540485 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => save best epoch due to training loss 0.8196947057540485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 2 / 50 , Similarity Loss : 0.6551430715183354 \n",
      " Epoch 2 / 50 , Similarity Loss : 0.6551430715183354 \n",
      " Epoch 2 / 50 , Similarity Loss : 0.6551430715183354 \n",
      " Epoch 2 / 50 , Similarity Loss : 0.6551430715183354 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => save best epoch due to training loss 0.6551430715183354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 3 / 50 , Similarity Loss : 0.6862332165303917 \n",
      " Epoch 3 / 50 , Similarity Loss : 0.6862332165303917 \n",
      " Epoch 3 / 50 , Similarity Loss : 0.6862332165303917 \n",
      " Epoch 3 / 50 , Similarity Loss : 0.6862332165303917 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 \n",
      " Epoch 4 / 50 , Similarity Loss : 0.5885542839546184 \n",
      " Epoch 4 / 50 , Similarity Loss : 0.5885542839546184 \n",
      " Epoch 4 / 50 , Similarity Loss : 0.5885542839546184 \n",
      " Epoch 4 / 50 , Similarity Loss : 0.5885542839546184 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => save best epoch due to training loss 0.5885542839546184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 5 / 50 , Similarity Loss : 0.5708655804301662 \n",
      " Epoch 5 / 50 , Similarity Loss : 0.5708655804301662 \n",
      " Epoch 5 / 50 , Similarity Loss : 0.5708655804301662 \n",
      " Epoch 5 / 50 , Similarity Loss : 0.5708655804301662 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => save best epoch due to training loss 0.5708655804301662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 6 / 50 , Similarity Loss : 0.5292383013087493 \n",
      " Epoch 6 / 50 , Similarity Loss : 0.5292383013087493 \n",
      " Epoch 6 / 50 , Similarity Loss : 0.5292383013087493 \n",
      " Epoch 6 / 50 , Similarity Loss : 0.5292383013087493 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => save best epoch due to training loss 0.5292383013087493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 7 / 50 , Similarity Loss : 0.4911677048284047 \n",
      " Epoch 7 / 50 , Similarity Loss : 0.4911677048284047 \n",
      " Epoch 7 / 50 , Similarity Loss : 0.4911677048284047 \n",
      " Epoch 7 / 50 , Similarity Loss : 0.4911677048284047 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => save best epoch due to training loss 0.4911677048284047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 8 / 50 , Similarity Loss : 0.5234432507200572 \n",
      " Epoch 8 / 50 , Similarity Loss : 0.5234432507200572 \n",
      " Epoch 8 / 50 , Similarity Loss : 0.5234432507200572 \n",
      " Epoch 8 / 50 , Similarity Loss : 0.5234432507200572 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 \n",
      " Epoch 9 / 50 , Similarity Loss : 0.5072363100781425 \n",
      " Epoch 9 / 50 , Similarity Loss : 0.5072363100781425 \n",
      " Epoch 9 / 50 , Similarity Loss : 0.5072363100781425 \n",
      " Epoch 9 / 50 , Similarity Loss : 0.5072363100781425 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 \n",
      " Epoch 10 / 50 , Similarity Loss : 0.4028790636080171 \n",
      " Epoch 10 / 50 , Similarity Loss : 0.4028790636080171 \n",
      " Epoch 10 / 50 , Similarity Loss : 0.4028790636080171 \n",
      " Epoch 10 / 50 , Similarity Loss : 0.4028790636080171 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => save best epoch due to training loss 0.4028790636080171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 11 / 50 , Similarity Loss : 0.43654710571472577 \n",
      " Epoch 11 / 50 , Similarity Loss : 0.43654710571472577 \n",
      " Epoch 11 / 50 , Similarity Loss : 0.43654710571472577 \n",
      " Epoch 11 / 50 , Similarity Loss : 0.43654710571472577 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 Learning rate = 0.0002 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-2de92a499fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_total\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from livelossplot import PlotLosses\n",
    "torch.cuda.empty_cache()\n",
    "model = model.to(DEVICE)\n",
    "scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True,min_lr=0.0000001)\n",
    "min_loss = 100000\n",
    "print(len(train_loader.dataset))\n",
    "log = []\n",
    "liveloss = PlotLosses()\n",
    "for epoch in range(0,num_epoch):\n",
    "    loss_total = 0\n",
    "    loss_total_cls = 0\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        d = data\n",
    "        query = d[0].to(DEVICE)\n",
    "        pos = d[1].to(DEVICE)\n",
    "        neg = d[2].to(DEVICE)\n",
    "        label = d[3].to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(query),model(pos),model(neg))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_total = (loss_total + loss.item()*batch_size)\n",
    "        \n",
    "    scheduler.step(loss_total)\n",
    "    logging.info(\"\\n Epoch {} / {} , Similarity Loss : {} \".format(epoch+1,num_epoch,loss_total/len(train_loader.dataset)))\n",
    "    logging.info(\"Learning rate = {} \".format(optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    if (loss_total <  min_loss):\n",
    "        min_loss = (loss_total)\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "        print(\" => save best epoch due to training loss {}\".format(min_loss/len(train_loader.dataset)))\n",
    "        \n",
    "    log.extend([min_loss/len(train_loader.dataset)])\n",
    "#     liveloss.update(log)\n",
    "#     liveloss.send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate training data for Classification Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (26): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (27): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (28): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (29): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (30): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (31): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.4, inplace=False)\n",
       "  (_fc): Sequential(\n",
       "    (0): Linear(in_features=1792, out_features=256, bias=True)\n",
       "  )\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reloading the model in the eval mode\n",
    "model = model.to(DEVICE)\n",
    "model.load_state_dict(torch.load('../models/20200630-1025_model.pt'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  1 10:03:11 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 49%   55C    P5    14W / 180W |    701MiB /  8119MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     10691      C   /home/hieu/torch/bin/python                  691MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1903, 256)\n",
      "(1902,)\n"
     ]
    }
   ],
   "source": [
    "# plotting a k nearest neighbor using sklearn\n",
    "# convert the learned features to numpy arrays\n",
    "model= model.to(DEVICE)\n",
    "features = np.empty((256,))\n",
    "labels = []\n",
    "for i,data in enumerate(train_loader):\n",
    "\n",
    "    samples = data[0].to(DEVICE)\n",
    "    label = data[3].to(DEVICE)\n",
    "    features = np.vstack((features,model(samples).cpu().detach().numpy()))\n",
    "    labels.extend(label.tolist())\n",
    "\n",
    "labels = np.array(labels)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1902, 256)\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.095999  0.049172 -0.009183 -0.015939  0.090810  0.036629 -0.150306   \n",
      "1 -0.123820  0.062414 -0.008314 -0.017740  0.108344  0.042550 -0.176775   \n",
      "2  0.113689 -0.059559 -0.032276 -0.006975 -0.098126 -0.013583  0.076281   \n",
      "3 -0.107438  0.051672 -0.009861 -0.016005  0.097750  0.038085 -0.160540   \n",
      "\n",
      "        7         8         9    ...       246       247       248       249  \\\n",
      "0  0.025182  0.024965  0.040963  ... -0.034861  0.078955  0.044701  0.034445   \n",
      "1  0.031382  0.021959  0.048678  ... -0.043658  0.094453  0.053028  0.046341   \n",
      "2 -0.006824  0.034024 -0.044886  ...  0.047861 -0.036896 -0.033450 -0.057313   \n",
      "3  0.026904  0.023728  0.041977  ... -0.035861  0.083344  0.047712  0.037116   \n",
      "\n",
      "        250       251       252       253       254       255  \n",
      "0  0.110727 -0.067206 -0.190206 -0.119013  0.020273 -0.132203  \n",
      "1  0.139846 -0.074684 -0.232696 -0.136537  0.023385 -0.160086  \n",
      "2 -0.121550  0.017673  0.141546  0.053083  0.008704  0.100846  \n",
      "3  0.122260 -0.066779 -0.207234 -0.124771  0.023781 -0.142905  \n",
      "\n",
      "[4 rows x 256 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.DataFrame(data=features[1:,:]    # values\n",
    "\n",
    "                          )\n",
    "print(features_df.shape)\n",
    "print(features_df.head(4))\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "features_data=pd.DataFrame(scaler.fit_transform(features_df))\n",
    "train_points = features_data.copy()\n",
    "train_points['label'] = labels\n",
    "train_points.to_csv(model_name+'train_points.csv')\n",
    "# fit to the knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "clf1 = KNeighborsClassifier(3)\n",
    "labels = pd.DataFrame(labels)\n",
    "# neigh = VotingClassifier(estimators=[('knn', clf1), ('gnb', clf2)],voting='hard')\n",
    "clf1.fit(features_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset:\n",
    "    def __init__(self, data, data_path, transform, training=True):\n",
    "        \"\"\"Define the dataset for classification problems\n",
    "\n",
    "        Args:\n",
    "            data ([dataframe]): [a dataframe that contain 2 columns: image name and label]\n",
    "            data_path ([str]): [path/to/folder that contains image file]\n",
    "            transform : [augmentation methods and transformation of images]\n",
    "            training (bool, optional): []. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.imgs = data[\"file_name\"].unique().tolist()\n",
    "        self.data_path = data_path\n",
    "        self.training = training\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.data_path, self.data.iloc[idx, 0]))\n",
    "        label = self.data.iloc[idx, 1]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test true labels and features\n",
    "def get_test_features(model,test_loader,DEVICE):\n",
    "    model.eval()\n",
    "    model = model.to(DEVICE)\n",
    "    test_features = np.empty((256,))\n",
    "    test_labels = []\n",
    "    for data,label in test_loader:\n",
    "        data = data.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        outputs = model(data)\n",
    "        test_features = np.vstack((test_features,outputs.cpu().detach().numpy()))\n",
    "        test_labels.extend(label)\n",
    "    test_labels = np.array(test_labels)   \n",
    "    print(test_features.shape)\n",
    "    print(test_labels.shape)\n",
    "    test_features_df = pd.DataFrame(data =test_features[1:,:])\n",
    "    return test_features_df,test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dc6e9d4d3450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hieu/notebooks'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 2)\n",
      "123\n",
      "(124, 256)\n",
      "(123,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      nohold       0.95      0.71      0.81        97\n",
      "        hold       0.44      0.85      0.58        26\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.69      0.78      0.70       123\n",
      "weighted avg       0.84      0.74      0.76       123\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fef647bf208>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test on TA data test - classification dataset\n",
    "test_lowres_data=pd.read_csv('../bhxanh/test.csv',usecols=[\"file_name\",\"label\"])\n",
    "test_lowres_data.file_name = test_lowres_data.file_name.str.replace(\"\\\\\",\"/\")\n",
    "# test_lowres_data['label'] = test_lowres_data['label'].map({'hold':1,'nohold':0})\n",
    "print(test_lowres_data.shape)\n",
    "test_lowres= ClassificationDataset(test_lowres_data,\"..\",no_transform)\n",
    "test_loader2 = torch.utils.data.DataLoader(test_lowres,batch_size=8,shuffle=False)\n",
    "print(len(test_loader2.dataset))\n",
    "low_res_features , low_res_labels = get_test_features(model,test_loader2,\"cpu\")\n",
    "test_points = low_res_features.copy()\n",
    "test_points['label'] = low_res_labels\n",
    "test_points.to_csv(model_name+'test_points_bhx_set.csv')\n",
    "low_res_features=scaler.transform(low_res_features)\n",
    "low_preds = clf1.predict(low_res_features)\n",
    "print(sklearn.metrics.classification_report(low_res_labels,low_preds,target_names=['nohold','hold']))\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf1, low_res_features, low_res_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 2)\n",
      "48\n",
      "(49, 256)\n",
      "(48,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      nohold       0.81      1.00      0.89        21\n",
      "        hold       1.00      0.81      0.90        27\n",
      "\n",
      "    accuracy                           0.90        48\n",
      "   macro avg       0.90      0.91      0.90        48\n",
      "weighted avg       0.92      0.90      0.90        48\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7ff052925d68>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test on TA data test - classification dataset\n",
    "test_lowres_data=pd.read_csv('../fail_set/fail_case.csv',usecols=[\"file_name\",\"label\"])\n",
    "test_lowres_data.file_name = test_lowres_data.file_name.str.replace(\"\\\\\",\"/\")\n",
    "# test_lowres_data['label'] = test_lowres_data['label'].map({'hold':1,'nohold':0})\n",
    "print(test_lowres_data.shape)\n",
    "test_lowres= ClassificationDataset(test_lowres_data,\"..\",no_transform)\n",
    "test_loader2 = torch.utils.data.DataLoader(test_lowres,batch_size=8,shuffle=False)\n",
    "print(len(test_loader2.dataset))\n",
    "low_res_features , low_res_labels = get_test_features(model,test_loader2,\"cpu\")\n",
    "test_points = low_res_features.copy()\n",
    "test_points['label'] = low_res_labels\n",
    "test_points.to_csv(model_name+'test_points_ta_set.csv')\n",
    "low_res_features=scaler.transform(low_res_features)\n",
    "low_preds = clf1.predict(low_res_features)\n",
    "print(sklearn.metrics.classification_report(low_res_labels,low_preds,target_names=['nohold','hold']))\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf1, low_res_features, low_res_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430, 2)\n",
      "430\n",
      "(431, 256)\n",
      "(430,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      nohold       0.96      0.88      0.92       327\n",
      "        hold       0.69      0.88      0.78       103\n",
      "\n",
      "    accuracy                           0.88       430\n",
      "   macro avg       0.83      0.88      0.85       430\n",
      "weighted avg       0.90      0.88      0.88       430\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f30cce563c8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test on test - classification dataset\n",
    "test_lowres_data=pd.read_csv('test.csv',usecols=[\"file_name\",\"label\"])\n",
    "test_lowres_data['label'] = test_lowres_data['label'].map({'hold':1,'nohold':0})\n",
    "print(test_lowres_data.shape)\n",
    "test_lowres= ClassificationDataset(test_lowres_data,'../test_data',no_transform)\n",
    "test_loader2 = torch.utils.data.DataLoader(test_lowres,batch_size=8,shuffle=False)\n",
    "print(len(test_loader2.dataset))\n",
    "low_res_features , low_res_labels = get_test_features(model,test_loader2,\"cpu\")\n",
    "test_points = low_res_features.copy()\n",
    "test_points['label'] = low_res_labels\n",
    "test_points.to_csv(model_name+'test_points.csv')\n",
    "low_res_features=scaler.transform(low_res_features)\n",
    "low_preds = clf1.predict(low_res_features)\n",
    "print(sklearn.metrics.classification_report(low_res_labels,low_preds,target_names=['nohold','hold']))\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf1, low_res_features, low_res_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
